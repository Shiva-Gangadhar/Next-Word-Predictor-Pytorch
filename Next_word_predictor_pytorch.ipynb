{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTzWlChxOil0a5Mf08iTSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiva-Gangadhar/Next-Word-Predictor-Pytorch/blob/main/Next_word_predictor_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c3YG23xCqSsg",
        "outputId": "91b5e105-02e7-4d8e-c0a7-ebfdf406a1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "JRDYhNjRwhry"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/dataset_book.txt\",\"r\", encoding = \"utf-8\") as file:\n",
        "  document = file.read()"
      ],
      "metadata": {
        "id": "qClkPimyxE2P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tW7Wm7IpyACz",
        "outputId": "495b40b9-8893-4e1b-8025-82036ad45cae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "xiB_JhQVyQs_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token]=len(vocab)"
      ],
      "metadata": {
        "id": "GCNTg5M8yghQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "0rFLBxgdzQUA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence,vocab):\n",
        "  numerical_sentences = []\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentences.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentences.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentences"
      ],
      "metadata": {
        "id": "dmDZwz2OzgNf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sequences = []\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sequences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))"
      ],
      "metadata": {
        "id": "IeLt3dC-z4dP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaRMX2aS8yjx",
        "outputId": "7d13b699-6523-455c-8f5d-ce7ed6126eb7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14413"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "\n",
        "for sentence in input_numerical_sequences:\n",
        "\n",
        "  for i in range(1,len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "GvCgZLrv9OIe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzPMo1be-UPv",
        "outputId": "eaff9809-b193-4cb2-f817-202b2d56a08a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134791"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_sequence = max(len(sequence) for sequence in training_sequence)\n",
        "print(max_length_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD--WRoK-uWP",
        "outputId": "dba6c4bb-5747-4854-c744-fbf93849f05f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "\n",
        "   padded_training_sequence.append([0]*(max_length_sequence-len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "ly4gVAwx_pkR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[0])\n",
        "padded_training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mARX09JTAV-A",
        "outputId": "5e97c0fa-2799-4740-a2fc-62ade6c2f073"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence , dtype=torch.long)"
      ],
      "metadata": {
        "id": "JoFh_9frAXqu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:, -1]"
      ],
      "metadata": {
        "id": "PpParpFVBWoB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,y):\n",
        "    self.x=x\n",
        "    self.y=y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "LEaosbElB7Cf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(x,y)"
      ],
      "metadata": {
        "id": "kKMzDAW8B72_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iVUhUCxDUOu",
        "outputId": "736f2614-50d9-4e37-c2c7-6b097dd87ef2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134791"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "L9ntcgUwDkqP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_cell_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "7r_kRqpuGvAA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTModel(len(vocab))"
      ],
      "metadata": {
        "id": "PrWJoaMvKUqb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1mx--vuKcOd",
        "outputId": "0d1a5de8-f878-4b65-f04d-53c82375313f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTModel(\n",
              "  (embedding): Embedding(7718, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=7718, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "MBl2ZL6uK_QN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss=0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y= batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss=total_loss+loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ktS4yJ_pLn8u",
        "outputId": "33fff67e-ec9a-45ab-c948-216dc0ff6b19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 4248.4779\n",
            "Epoch: 2, Loss: 3865.4048\n",
            "Epoch: 3, Loss: 3821.7661\n",
            "Epoch: 4, Loss: 3783.6457\n",
            "Epoch: 5, Loss: 3781.4608\n",
            "Epoch: 6, Loss: 3728.6767\n",
            "Epoch: 7, Loss: 3716.2235\n",
            "Epoch: 8, Loss: 3708.2423\n",
            "Epoch: 9, Loss: 3688.0067\n",
            "Epoch: 10, Loss: 3666.9441\n",
            "Epoch: 11, Loss: 3665.4220\n",
            "Epoch: 12, Loss: 3650.2961\n",
            "Epoch: 13, Loss: 3630.7963\n",
            "Epoch: 14, Loss: 3627.6593\n",
            "Epoch: 15, Loss: 3620.7096\n",
            "Epoch: 16, Loss: 3601.4918\n",
            "Epoch: 17, Loss: 3602.9764\n",
            "Epoch: 18, Loss: 3575.1214\n",
            "Epoch: 19, Loss: 3566.6444\n",
            "Epoch: 20, Loss: 3568.0377\n",
            "Epoch: 21, Loss: 3577.1904\n",
            "Epoch: 22, Loss: 3554.3042\n",
            "Epoch: 23, Loss: 3557.4251\n",
            "Epoch: 24, Loss: 3543.3826\n",
            "Epoch: 25, Loss: 3552.0944\n",
            "Epoch: 26, Loss: 3515.3904\n",
            "Epoch: 27, Loss: 3521.7903\n",
            "Epoch: 28, Loss: 3496.3696\n",
            "Epoch: 29, Loss: 3508.8561\n",
            "Epoch: 30, Loss: 3503.9106\n",
            "Epoch: 31, Loss: 3491.5600\n",
            "Epoch: 32, Loss: 3475.1335\n",
            "Epoch: 33, Loss: 3494.6221\n",
            "Epoch: 34, Loss: 3476.6356\n",
            "Epoch: 35, Loss: 3490.9594\n",
            "Epoch: 36, Loss: 3483.1051\n",
            "Epoch: 37, Loss: 3483.9592\n",
            "Epoch: 38, Loss: 3463.8448\n",
            "Epoch: 39, Loss: 3462.7046\n",
            "Epoch: 40, Loss: 3480.8132\n",
            "Epoch: 41, Loss: 3457.8344\n",
            "Epoch: 42, Loss: 3468.9537\n",
            "Epoch: 43, Loss: 3459.2181\n",
            "Epoch: 44, Loss: 3456.1116\n",
            "Epoch: 45, Loss: 3453.9208\n",
            "Epoch: 46, Loss: 3458.9773\n",
            "Epoch: 47, Loss: 3457.7970\n",
            "Epoch: 48, Loss: 3454.9392\n",
            "Epoch: 49, Loss: 3407.1118\n",
            "Epoch: 50, Loss: 3429.2538\n",
            "Epoch: 51, Loss: 3454.9158\n",
            "Epoch: 52, Loss: 3411.7346\n",
            "Epoch: 53, Loss: 3425.4980\n",
            "Epoch: 54, Loss: 3437.5770\n",
            "Epoch: 55, Loss: 3459.7178\n",
            "Epoch: 56, Loss: 3436.0267\n",
            "Epoch: 57, Loss: 3436.0573\n",
            "Epoch: 58, Loss: 3415.4192\n",
            "Epoch: 59, Loss: 3422.5599\n",
            "Epoch: 60, Loss: 3435.1327\n",
            "Epoch: 61, Loss: 3420.5078\n",
            "Epoch: 62, Loss: 3435.4838\n",
            "Epoch: 63, Loss: 3436.0455\n",
            "Epoch: 64, Loss: 3428.9167\n",
            "Epoch: 65, Loss: 3423.3531\n",
            "Epoch: 66, Loss: 3452.0955\n",
            "Epoch: 67, Loss: 3424.9304\n",
            "Epoch: 68, Loss: 3439.4200\n",
            "Epoch: 69, Loss: 3417.5101\n",
            "Epoch: 70, Loss: 3432.4915\n",
            "Epoch: 71, Loss: 3444.1517\n",
            "Epoch: 72, Loss: 3424.0180\n",
            "Epoch: 73, Loss: 3432.3034\n",
            "Epoch: 74, Loss: 3416.3213\n",
            "Epoch: 75, Loss: 3440.9833\n",
            "Epoch: 76, Loss: 3422.2141\n",
            "Epoch: 77, Loss: 3447.9722\n",
            "Epoch: 78, Loss: 3442.5709\n",
            "Epoch: 79, Loss: 3455.6773\n",
            "Epoch: 80, Loss: 3418.0418\n",
            "Epoch: 81, Loss: 3448.9599\n",
            "Epoch: 82, Loss: 3432.0541\n",
            "Epoch: 83, Loss: 3417.9714\n",
            "Epoch: 84, Loss: 3444.7284\n",
            "Epoch: 85, Loss: 3395.2641\n",
            "Epoch: 86, Loss: 3445.4302\n",
            "Epoch: 87, Loss: 3407.0892\n",
            "Epoch: 88, Loss: 3428.8994\n",
            "Epoch: 89, Loss: 3412.6136\n",
            "Epoch: 90, Loss: 3417.3301\n",
            "Epoch: 91, Loss: 3427.4794\n",
            "Epoch: 92, Loss: 3434.9327\n",
            "Epoch: 93, Loss: 3417.5828\n",
            "Epoch: 94, Loss: 3426.4660\n",
            "Epoch: 95, Loss: 3434.2748\n",
            "Epoch: 96, Loss: 3455.6299\n",
            "Epoch: 97, Loss: 3437.2709\n",
            "Epoch: 98, Loss: 3419.8232\n",
            "Epoch: 99, Loss: 3435.7585\n",
            "Epoch: 100, Loss: 3426.0923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, vocab, text):\n",
        "\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "\n",
        "  padded_text = torch.tensor([0]*(max_length_sequence-len(numerical_text))+numerical_text,dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "  output = model(padded_text)\n",
        "\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  return text + \" \" + list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "qrrVk4myNRU-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"I was seized with a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PD-fJG_QMqkT",
        "outputId": "ab6bc94b-479a-4fdf-86d8-86369f3c7f0e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was seized with a young'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"I do not know\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFRDNfSFM73T",
        "outputId": "6f24b84e-0f4d-4c2a-ab52-297dcc9eb165"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not know what\n",
            "I do not know what a\n",
            "I do not know what a occasion\n",
            "I do not know what a occasion required\n",
            "I do not know what a occasion required .\n",
            "I do not know what a occasion required . i\n",
            "I do not know what a occasion required . i pity\n",
            "I do not know what a occasion required . i pity you\n",
            "I do not know what a occasion required . i pity you ,\n",
            "I do not know what a occasion required . i pity you , my\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "mOx0Vkw6QCvX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wkgnV7jQj5m",
        "outputId": "97b687d0-b858-4f42-cd8a-d538b7c86750"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 82.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reFkNMNnQluE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}